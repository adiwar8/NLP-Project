{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlNF-_DjfgtK"
      },
      "source": [
        "\n",
        "# **Install libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04jwVrdr9sdb",
        "outputId": "c3d8f8b0-81fd-4368-8f56-58d0a038d2a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGiskWK4_6b-",
        "outputId": "605a927d-8447-45ac-846b-7a425c234e5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.9/dist-packages (2.11.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (4.65.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (1.5.3)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from datasets) (1.22.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from datasets) (23.1)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.9/dist-packages (from datasets) (3.2.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (2.27.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (2023.4.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from datasets) (3.8.4)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.9/dist-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.14.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (1.9.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.11.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (3.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets tqdm pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_d8OEpLA5Aii",
        "outputId": "a06f5b0a-bc8d-40d5-933e-fccaeafcd98c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.9/dist-packages (0.1.98)\n"
          ]
        }
      ],
      "source": [
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjKf77Z7EYpk",
        "outputId": "f5fa3bc3-63d2-429b-d225-d234cdd00903"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.28.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.11.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.14.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0OaSKNC3AvaX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pn-G_eUwFovO",
        "outputId": "d4c5da79-589f-4c43-fc74-e9f0c4ae59cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Apr 25 13:20:51 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   54C    P8    12W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# Check we have a GPU and check the memory size of the GPU\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0n55Ex1Bl2k"
      },
      "source": [
        "# **Import packages**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ht8Fu9U2-IRG",
        "outputId": "5ccb0af4-4692-486a-bacc-bcf828dcf41e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import argparse\n",
        "import glob\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import logging\n",
        "import random\n",
        "import re\n",
        "from itertools import chain\n",
        "from string import punctuation\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from transformers import (\n",
        "    AdamW,\n",
        "    T5ForConditionalGeneration,\n",
        "    T5Tokenizer,\n",
        "    get_linear_schedule_with_warmup\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ykds8V47B1XT"
      },
      "source": [
        "# **Set a seed**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "p03e0mY13jdV"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "CyrYjMFREUCn"
      },
      "outputs": [],
      "source": [
        "def set_seed(seed):\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "\n",
        "set_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7YZhzbl88AE"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "# ***C4-200M dataset***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "bYqzCt4mfkoc"
      },
      "outputs": [],
      "source": [
        "pd.set_option('display.max_colwidth', None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWQZdyVlfLL_",
        "outputId": "5293726a-08c0-4df3-a762-f8f522a73794"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100000, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/c4_200m/c4_200m_550k.csv')\n",
        "df = df[0:100000]\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "8AcvjhlVfPe2",
        "outputId": "0663d804-a8a6-4098-843c-dc6708175775"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                                                   input  \\\n",
              "0    The steps below describe how to remove data for one or more specifies areas and how to put on the data from a snapshot to the index   \n",
              "1                                              When I wake up it\\'s usually comes out dreamsI\\'m thinking so my thoughts are very weird.   \n",
              "2  One of the cardinal factors to be considered trying to decide on which kind of shipping to customer settle is the! market difference.   \n",
              "3                                                                Answers » Regions » Is in Nagorno-Karabakt region that part in Armenia?   \n",
              "4                                                                                                   Flaneuring in fun at maple creek SK!   \n",
              "\n",
              "                                                                                                                                   output  \n",
              "0  The steps below describe how to remove data for one ore more specific areas and how to put back the data from a snapshot to the index.  \n",
              "1                                                  When I wake up it\\'s usually dreams I\\'m thinking about so my thoughts are very weird.  \n",
              "2         One of the cardinal factors to consider when trying to decide on which kind of shipping to settle for is the market difference.  \n",
              "3                                                                         Answers » Regions » Is Nagorno-Karabakh region part of Armenia?  \n",
              "4                                                                                                       Flaneuring Fun in Maple Creek SK!  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-567839ad-05d9-457f-9407-5ae382c9f72c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input</th>\n",
              "      <th>output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The steps below describe how to remove data for one or more specifies areas and how to put on the data from a snapshot to the index</td>\n",
              "      <td>The steps below describe how to remove data for one ore more specific areas and how to put back the data from a snapshot to the index.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>When I wake up it\\'s usually comes out dreamsI\\'m thinking so my thoughts are very weird.</td>\n",
              "      <td>When I wake up it\\'s usually dreams I\\'m thinking about so my thoughts are very weird.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>One of the cardinal factors to be considered trying to decide on which kind of shipping to customer settle is the! market difference.</td>\n",
              "      <td>One of the cardinal factors to consider when trying to decide on which kind of shipping to settle for is the market difference.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Answers » Regions » Is in Nagorno-Karabakt region that part in Armenia?</td>\n",
              "      <td>Answers » Regions » Is Nagorno-Karabakh region part of Armenia?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Flaneuring in fun at maple creek SK!</td>\n",
              "      <td>Flaneuring Fun in Maple Creek SK!</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-567839ad-05d9-457f-9407-5ae382c9f72c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-567839ad-05d9-457f-9407-5ae382c9f72c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-567839ad-05d9-457f-9407-5ae382c9f72c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "6ANFcc6SE0p2"
      },
      "outputs": [],
      "source": [
        "from transformers import (\n",
        "    T5ForConditionalGeneration, T5Tokenizer, \n",
        "    Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq\n",
        "  )\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35po7q9CE57P",
        "outputId": "1f6a241c-0ecf-4f5e-8933-7ffa614cb2b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/models/t5/tokenization_t5.py:163: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
            "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
            "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
            "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
            "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model_name = 't5-base'\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "a75jy7E1igUi"
      },
      "outputs": [],
      "source": [
        "def calc_token_len(example):\n",
        "    return len(tokenizer(example).input_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyMhxBbjYN-u",
        "outputId": "6b73a904-fa5d-44d1-8f10-ce694889359c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((90000, 2), (10000, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_df, test_df = train_test_split(df, test_size=0.10, shuffle=True)\n",
        "train_df.shape, test_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uruzAQuujAeA",
        "outputId": "532eed3d-5e81-4aa2-86b6-66dcb26b7f9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (879 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        }
      ],
      "source": [
        "test_df['input_token_len'] = test_df['input'].apply(calc_token_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "oNvjbMF3jWkW",
        "outputId": "826cde0a-12c5-446f-e94b-39662288a2c7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                                                         input  \\\n",
              "75721                       A European space agency of astronauts, Tim Peake, will run the London Marathon of the International Space Station.   \n",
              "80184  26 .. 26  31  316 Duncan         Pauline        9     F    .    .              .         Ill               .      .of X     .    .    .   \n",
              "19864                                                                         Have there have new shows starting this summer that interest us?   \n",
              "76699                                                                 speedily guaranteed to be secured to the frontal in your camcorder lens.   \n",
              "92991                                                                              Click here for watching Emmi’s presentation about her work.   \n",
              "\n",
              "                                                                                                                              output  \\\n",
              "75721               A European Space Agency astronaut, Tim Peake, will run the London Marathon from the International Space Station.   \n",
              "80184  26  314  316 Duncan         Pauline        9     F    .    .              .         Ill               .     X     .    .    .   \n",
              "19864                                                                Are there any new shows starting this summer that interest you?   \n",
              "76699                                                                         speedily secure to the frontal of your camcorder lens.   \n",
              "92991                                                                           Click here to watch Emmi’s presentation on her work.   \n",
              "\n",
              "       input_token_len  \n",
              "75721               24  \n",
              "80184               35  \n",
              "19864               13  \n",
              "76699               18  \n",
              "92991               15  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7dd9b1ec-8844-421d-83ab-e8f1bfce4d1c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input</th>\n",
              "      <th>output</th>\n",
              "      <th>input_token_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>75721</th>\n",
              "      <td>A European space agency of astronauts, Tim Peake, will run the London Marathon of the International Space Station.</td>\n",
              "      <td>A European Space Agency astronaut, Tim Peake, will run the London Marathon from the International Space Station.</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80184</th>\n",
              "      <td>26 .. 26  31  316 Duncan         Pauline        9     F    .    .              .         Ill               .      .of X     .    .    .</td>\n",
              "      <td>26  314  316 Duncan         Pauline        9     F    .    .              .         Ill               .     X     .    .    .</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19864</th>\n",
              "      <td>Have there have new shows starting this summer that interest us?</td>\n",
              "      <td>Are there any new shows starting this summer that interest you?</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76699</th>\n",
              "      <td>speedily guaranteed to be secured to the frontal in your camcorder lens.</td>\n",
              "      <td>speedily secure to the frontal of your camcorder lens.</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92991</th>\n",
              "      <td>Click here for watching Emmi’s presentation about her work.</td>\n",
              "      <td>Click here to watch Emmi’s presentation on her work.</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7dd9b1ec-8844-421d-83ab-e8f1bfce4d1c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7dd9b1ec-8844-421d-83ab-e8f1bfce4d1c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7dd9b1ec-8844-421d-83ab-e8f1bfce4d1c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "test_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qy3eyFHxjZWm",
        "outputId": "9beed616-5521-4a08-b083-5faa18ac1e9e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    10000.000000\n",
              "mean        33.652800\n",
              "std         26.646506\n",
              "min          5.000000\n",
              "25%         17.000000\n",
              "50%         27.000000\n",
              "75%         42.000000\n",
              "max        879.000000\n",
              "Name: input_token_len, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "test_df['input_token_len'].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hz7cdWnr_OO"
      },
      "source": [
        "### We will use a token length of 64 since it will cover the vast majority of examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "rSvsHw6HeHrl"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "test_dataset = Dataset.from_pandas(test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfRhXHBGoiiU",
        "outputId": "fc6d8eae-f593-4883-bb0c-615f9c054c03"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['input', 'output', 'input_token_len', '__index_level_0__'],\n",
              "    num_rows: 10000\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "test_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onckS0qK4kTF"
      },
      "source": [
        "### Load the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "hDjTyQH75OKH"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "class GrammarDataset(Dataset):\n",
        "    def __init__(self, dataset, tokenizer,print_text=False):         \n",
        "        self.dataset = dataset\n",
        "        self.pad_to_max_length = False\n",
        "        self.tokenizer = tokenizer\n",
        "        self.print_text = print_text\n",
        "        self.max_len = 64\n",
        "  \n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "\n",
        "    def tokenize_data(self, example):\n",
        "        input_, target_ = example['input'], example['output']\n",
        "\n",
        "        # tokenize inputs\n",
        "        tokenized_inputs = tokenizer(input_, pad_to_max_length=self.pad_to_max_length, \n",
        "                                            max_length=self.max_len,\n",
        "                                            return_attention_mask=True)\n",
        "    \n",
        "        tokenized_targets = tokenizer(target_, pad_to_max_length=self.pad_to_max_length, \n",
        "                                            max_length=self.max_len,\n",
        "                                            return_attention_mask=True)\n",
        "\n",
        "        inputs={\"input_ids\": tokenized_inputs['input_ids'],\n",
        "            \"attention_mask\": tokenized_inputs['attention_mask'],\n",
        "            \"labels\": tokenized_targets['input_ids']\n",
        "        }\n",
        "        \n",
        "        return inputs\n",
        "\n",
        "  \n",
        "    def __getitem__(self, index):\n",
        "        inputs = self.tokenize_data(self.dataset[index])\n",
        "        \n",
        "        if self.print_text:\n",
        "            for k in inputs.keys():\n",
        "                print(k, len(inputs[k]))\n",
        "\n",
        "        return inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlkkfaIS64lZ",
        "outputId": "39fe8056-abce-4d78-fe9d-56e7b89158cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_ids 40\n",
            "attention_mask 40\n",
            "labels 40\n",
            "{'input_ids': [5740, 1823, 23, 16331, 5, 41, 1161, 2715, 7, 6, 4475, 61, 431, 10, 419, 12760, 8, 2743, 22, 7, 3251, 441, 97, 192, 676, 21, 1107, 30, 68, 1381, 16, 3, 9, 1158, 13, 23772, 7, 1766, 5, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [5740, 1823, 23, 16331, 41, 1161, 2715, 7, 6, 4475, 61, 10, 431, 3, 18, 419, 12760, 8, 2743, 22, 7, 3251, 441, 192, 676, 13, 1107, 30, 68, 1381, 16, 3, 9, 1158, 13, 23772, 7, 1766, 5, 1]}\n"
          ]
        }
      ],
      "source": [
        "dataset = GrammarDataset(test_dataset, tokenizer, True)\n",
        "print(dataset[121])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17tTZNRU9Nbd"
      },
      "source": [
        "### Define Evaluator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAYzYHBR9Pj2",
        "outputId": "74bf9e8c-5902-4be7-e38e-105deed04c85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.9/dist-packages (0.1.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.9/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.9/dist-packages (from rouge_score) (1.16.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (from rouge_score) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from rouge_score) (1.22.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk->rouge_score) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.9/dist-packages (from nltk->rouge_score) (2022.10.31)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk->rouge_score) (8.1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from nltk->rouge_score) (4.65.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install rouge_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "ojPxcaxr9P_o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09799a5b-a3ab-4016-c655-2101cd174833"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-76fa4d2ef6b0>:2: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
            "  rouge_metric = load_metric(\"rouge\")\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_metric\n",
        "rouge_metric = load_metric(\"rouge\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlkEgSrq9lxJ"
      },
      "source": [
        "### Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "5x4_f3P79oCK"
      },
      "outputs": [],
      "source": [
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, padding='longest', return_tensors='pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "L2P-wbva3Ibt"
      },
      "outputs": [],
      "source": [
        "os.environ[\"WANDB_DISABLED\"] = \"true\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "rc-YLKSK9pkA"
      },
      "outputs": [],
      "source": [
        "# defining training related arguments\n",
        "batch_size = 16\n",
        "args = Seq2SeqTrainingArguments(output_dir=\"./weights\",\n",
        "                        evaluation_strategy=\"steps\",\n",
        "                        per_device_train_batch_size=batch_size,\n",
        "                        per_device_eval_batch_size=batch_size,\n",
        "                        learning_rate=2e-5,\n",
        "                        num_train_epochs=1,\n",
        "                        weight_decay=0.01,\n",
        "                        save_total_limit=2,\n",
        "                        predict_with_generate=True,\n",
        "                        fp16 = True,\n",
        "                        gradient_accumulation_steps = 6,\n",
        "                        eval_steps = 500,\n",
        "                        save_steps = 500,\n",
        "                        load_best_model_at_end=True,\n",
        "                        logging_dir=\"/logs\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YutXc8Q1-DG2",
        "outputId": "503af110-dd3f-4240-becf-880bb467536d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import numpy as np\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    # Replace -100 in the labels as we can't decode them.\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "    \n",
        "    # Rouge expects a newline after each sentence\n",
        "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
        "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
        "    \n",
        "    result = rouge_metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
        "    # Extract a few results\n",
        "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
        "    \n",
        "    # Add mean generated length\n",
        "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "    return {k: round(v, 4) for k, v in result.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "fyOdMJQW-FFJ"
      },
      "outputs": [],
      "source": [
        "# defining trainer using 🤗\n",
        "trainer = Seq2SeqTrainer(model=model, \n",
        "                args=args, \n",
        "                train_dataset= GrammarDataset(train_dataset, tokenizer),\n",
        "                eval_dataset=GrammarDataset(test_dataset, tokenizer),\n",
        "                tokenizer=tokenizer,\n",
        "                data_collator=data_collator,\n",
        "                compute_metrics=compute_metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "a_JO3oUR-G10",
        "outputId": "870cd879-ce90-4d83-cb88-dde170100aa7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='937' max='937' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [937/937 30:13, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge1</th>\n",
              "      <th>Rouge2</th>\n",
              "      <th>Rougel</th>\n",
              "      <th>Rougelsum</th>\n",
              "      <th>Gen Len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.775800</td>\n",
              "      <td>0.630679</td>\n",
              "      <td>71.494400</td>\n",
              "      <td>61.204400</td>\n",
              "      <td>70.759500</td>\n",
              "      <td>70.781100</td>\n",
              "      <td>17.291200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=937, training_loss=0.7395562138348786, metrics={'train_runtime': 1815.228, 'train_samples_per_second': 49.581, 'train_steps_per_second': 0.516, 'total_flos': 6628925297295360.0, 'train_loss': 0.7395562138348786, 'epoch': 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "yIkeGbykntXp"
      },
      "outputs": [],
      "source": [
        "trainer.save_model('t5_gec_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "uvoTQ_e-nyqi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9672e46-1020-423d-b99c-6e523b7c4c97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: t5_gec_model/ (stored 0%)\n",
            "  adding: t5_gec_model/config.json (deflated 62%)\n",
            "  adding: t5_gec_model/training_args.bin (deflated 49%)\n",
            "  adding: t5_gec_model/pytorch_model.bin (deflated 9%)\n",
            "  adding: t5_gec_model/special_tokens_map.json (deflated 86%)\n",
            "  adding: t5_gec_model/tokenizer_config.json (deflated 83%)\n",
            "  adding: t5_gec_model/spiece.model (deflated 48%)\n",
            "  adding: t5_gec_model/generation_config.json (deflated 29%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r 't5_gec_model.zip' 't5_gec_model'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "ZkutuP4Tn3j1"
      },
      "outputs": [],
      "source": [
        "!mv t5_gec_model.zip /content/drive/MyDrive/c4_200m"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjfvFEgEiXgR"
      },
      "source": [
        "I have uploaded this model to HuggingFace Model Zoo and we can run inference using it"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQzJE6ybKPaR"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqDyDu5GKOrg"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "model_name = 'deep-learning-analytics/GrammarCorrector'\n",
        "torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_name).to(torch_device)\n",
        "\n",
        "def correct_grammar(input_text,num_return_sequences):\n",
        "  batch = tokenizer([input_text],truncation=True,padding='max_length',max_length=64, return_tensors=\"pt\").to(torch_device)\n",
        "  translated = model.generate(**batch,max_length=64,num_beams=4, num_return_sequences=num_return_sequences, temperature=1.5)\n",
        "  tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
        "  return tgt_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "--u_Cu-T3y9g"
      },
      "outputs": [],
      "source": [
        "def correct_grammar(input_text,num_return_sequences):\n",
        "  batch = tokenizer([input_text],truncation=True,padding='max_length',max_length=64, return_tensors=\"pt\").to('cuda')\n",
        "  translated = model.generate(**batch,max_length=64,num_beams=4, num_return_sequences=num_return_sequences, temperature=1.5)\n",
        "  tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
        "  return tgt_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMm8PGpMhYxl",
        "outputId": "551f8474-b388-435f-ee77-ae8886abb753"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['He is moving here.', 'He are moving here.']\n"
          ]
        }
      ],
      "source": [
        "text = 'He are moving here.'\n",
        "print(correct_grammar(text, num_return_sequences=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "8qLMT5DyvsKT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72f652a9-38db-4600-f2cd-feb78351dc9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Cat drinked milk and drank milk. Cat drank milk and drank milk. Cat drank milk. Cat drank milk. Cat drank milk. Cat drank milk. Cat drank milk. Cat drank milk. Cat drank milk']\n"
          ]
        }
      ],
      "source": [
        "text = 'Cat drinked milk'\n",
        "print(correct_grammar(text, num_return_sequences=1))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}